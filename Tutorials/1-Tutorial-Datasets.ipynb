{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e378902e-2160-42ae-bdfb-1c9bf204459f",
   "metadata": {},
   "source": [
    "# Building the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3966ee-b553-4319-9ce5-7f0e62e487bb",
   "metadata": {},
   "source": [
    "In this tutorial we provide the instructions to build the two datasets we have used to train the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93163ac1-cc90-4fba-a023-01f3dbf15727",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52cbb3-9c72-4163-8c38-b3e2f9dd7bbf",
   "metadata": {},
   "source": [
    "First we will download the folders that contain the CA coordinates of the experimental structures and the txt file with the pdb codes of every protein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85809311-2bbb-44c9-ad5f-c5a3f56901a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmdexp.datasets.proteinfactory import ProteinFactory\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c8a69f-c105-4423-926f-b82054036cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_path = '../data/datasets'\n",
    "output_path = '.'\n",
    "notebook_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce3a3e5-c89f-4de2-b4b9-0ad5f3304a34",
   "metadata": {},
   "source": [
    "### Fast-folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0085514-bd1d-42ff-8a62-53ca7135ee18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(os.path.join(datasets_path, 'fastfolders.tar.gz')) as tar:\n",
    "    tar.extractall(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5964150e-3641-4abe-ba21-0bbf85a108b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 12/12 [00:00<00:00, 13.85it/s]\n"
     ]
    }
   ],
   "source": [
    "protein_factory = ProteinFactory()\n",
    "protein_factory.create_dataset(dataset = os.path.join(notebook_dir, 'fastfolders/ff.txt'), \n",
    "                               data_dir = os.path.join(notebook_dir, 'fastfolders/ff'),\n",
    "                               out_dir = os.path.join(notebook_dir, 'fastfolders/ff.npy')\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d101fc8-1b2d-45e7-bdf5-e369e5b14349",
   "metadata": {},
   "source": [
    "### Computational Solved Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3750922-9224-4a91-baa1-0f24a3cf3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tarfile.open(os.path.join(datasets_path, 'csm_50.tar.gz')) as tar:\n",
    "    tar.extractall(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9ed6d70-2533-409e-ba29-a8c566be5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 15021/15021 [07:49<00:00, 31.99it/s]\n"
     ]
    }
   ],
   "source": [
    "protein_factory = ProteinFactory()\n",
    "protein_factory.create_dataset(dataset = os.path.join(notebook_dir, 'csm_50/csm_50.txt'), \n",
    "                               data_dir = os.path.join(notebook_dir, 'csm_50/csm_dataset_50'),\n",
    "                               out_dir = os.path.join(notebook_dir, 'csm_50/csm_50.npy')\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1a6eab-88fe-4f70-9943-8e7f033b4fd4",
   "metadata": {},
   "source": [
    "Now we have prepared the datasets for training our models. Custom datasets can be created with pdb structures, only a folder that contains a subfolder x_0 with pdb structures and a .txt \n",
    "file with the names of the structures that the user wants to use are needed to create new datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchmd-exp",
   "language": "python",
   "name": "torchmd-exp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
